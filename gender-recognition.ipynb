{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\nimport PIL.Image as Image\nimport pathlib\nimport os\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nfrom tensorflow import keras\nfrom keras.preprocessing import image\nfrom tensorflow.keras.utils import img_to_array\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-23T21:32:15.691011Z","iopub.execute_input":"2022-09-23T21:32:15.691482Z","iopub.status.idle":"2022-09-23T21:32:15.699139Z","shell.execute_reply.started":"2022-09-23T21:32:15.691438Z","shell.execute_reply":"2022-09-23T21:32:15.698110Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Get directory path to Training dataset\ntrain_dir = pathlib.Path('../input/gender-recognition-dataset/Gender Recognition Dataset/Training')\n# Get a list of all images in the Training dataset\ntrain_image_paths = list(train_dir.glob(r'**/*.jpg'))\n\n# Get directory path to Validation dataset\nvalid_dir = pathlib.Path('../input/gender-recognition-dataset/Gender Recognition Dataset/Validation')\n# Get a list of all images in the Validation dataset\nvalid_image_paths = list(valid_dir.glob(r'**/*.jpg'))","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:32:17.405127Z","iopub.execute_input":"2022-09-23T21:32:17.405484Z","iopub.status.idle":"2022-09-23T21:32:38.516856Z","shell.execute_reply.started":"2022-09-23T21:32:17.405453Z","shell.execute_reply":"2022-09-23T21:32:38.515864Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Image Processing","metadata":{}},{"cell_type":"code","source":"# Create a function to extract the labels from image filepath\ndef image_processing(filepath):\n    labels = [str(filepath[i]).split('/')[-2]\n             for i in range(len(filepath))]\n    \n    # Create a DataFrame and input the filepath and labels\n    filepath = pd.Series(filepath, name = 'Filepath').astype(str)\n    labels = pd.Series(labels, name = 'Label')\n    \n    df = pd.concat([filepath, labels], axis='columns')\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:32:38.518904Z","iopub.execute_input":"2022-09-23T21:32:38.519616Z","iopub.status.idle":"2022-09-23T21:32:38.526659Z","shell.execute_reply.started":"2022-09-23T21:32:38.519577Z","shell.execute_reply":"2022-09-23T21:32:38.525661Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Create a train and validation DataFrame\ntrain_df = image_processing(train_image_paths)\nval_df = image_processing(valid_image_paths)","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:32:38.528482Z","iopub.execute_input":"2022-09-23T21:32:38.529393Z","iopub.status.idle":"2022-09-23T21:32:38.722423Z","shell.execute_reply.started":"2022-09-23T21:32:38.529356Z","shell.execute_reply":"2022-09-23T21:32:38.721482Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Create DataFrame with just one label for each label\ndf_unique = train_df.copy().drop_duplicates(subset=['Label']).reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:32:38.724817Z","iopub.execute_input":"2022-09-23T21:32:38.725150Z","iopub.status.idle":"2022-09-23T21:32:38.738942Z","shell.execute_reply.started":"2022-09-23T21:32:38.725114Z","shell.execute_reply":"2022-09-23T21:32:38.737951Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Generate new images from dataset\ntrain_generator = tf.keras.preprocessing.image.ImageDataGenerator(\npreprocessing_function = tf.keras.applications.mobilenet_v3.preprocess_input\n)\n\nval_generator = tf.keras.preprocessing.image.ImageDataGenerator(\npreprocessing_function = tf.keras.applications.mobilenet_v3.preprocess_input\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:32:38.740582Z","iopub.execute_input":"2022-09-23T21:32:38.741139Z","iopub.status.idle":"2022-09-23T21:32:38.747341Z","shell.execute_reply.started":"2022-09-23T21:32:38.741103Z","shell.execute_reply":"2022-09-23T21:32:38.746175Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Generate images using 'train_df' DataFrame\ntrain_images = train_generator.flow_from_dataframe(\n    dataframe  = train_df,\n    x_col = 'Filepath',\n    y_col = 'Label',\n    target_size = (224, 224),\n    color_mode = 'rgb',\n    class_mode = 'categorical',\n    batch_size = 32,\n    shuffle = True,\n    seed = 0,\n    rotation_range = 30,\n    zoom_range = 0.15,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.15,\n    horizontal_flip = True,\n    fill_mode = 'nearest'\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:32:38.749110Z","iopub.execute_input":"2022-09-23T21:32:38.749537Z","iopub.status.idle":"2022-09-23T21:32:44.830778Z","shell.execute_reply.started":"2022-09-23T21:32:38.749501Z","shell.execute_reply":"2022-09-23T21:32:44.829751Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Found 47406 validated image filenames belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Generate images using 'val_df' DataFrame\nval_images = train_generator.flow_from_dataframe(\n    dataframe  = val_df,\n    x_col = 'Filepath',\n    y_col = 'Label',\n    target_size = (224, 224),\n    color_mode = 'rgb',\n    class_mode = 'categorical',\n    batch_size = 32,\n    shuffle = True,\n    seed = 0,\n    rotation_range = 30,\n    zoom_range = 0.15,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.15,\n    horizontal_flip = True,\n    fill_mode = 'nearest'\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:32:44.832126Z","iopub.execute_input":"2022-09-23T21:32:44.832762Z","iopub.status.idle":"2022-09-23T21:32:45.626229Z","shell.execute_reply.started":"2022-09-23T21:32:44.832724Z","shell.execute_reply":"2022-09-23T21:32:45.625125Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Found 11831 validated image filenames belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Use Tensorflow pretrained model\npretrained_model = tf.keras.applications.MobileNetV3Small(\ninput_shape= (224, 224, 3),\ninclude_top = False,\nweights = 'imagenet',\npooling = 'avg'\n)\n\n# Freeze weights\npretrained_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:32:45.628491Z","iopub.execute_input":"2022-09-23T21:32:45.629429Z","iopub.status.idle":"2022-09-23T21:32:46.691074Z","shell.execute_reply.started":"2022-09-23T21:32:45.629389Z","shell.execute_reply":"2022-09-23T21:32:46.690092Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Create weights\ninputs = pretrained_model.input\n\nx = tf.keras.layers.Dense(128, activation = 'relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, activation = 'relu')(x)\n\noutputs = tf.keras.layers.Dense(2, activation = 'softmax')(x)\n\nmodel = tf.keras.Model(inputs = inputs, outputs = outputs)\n\nmodel.compile(\n    optimizer = 'adam',\n    loss = 'categorical_crossentropy',\n    metrics = ['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:32:46.692727Z","iopub.execute_input":"2022-09-23T21:32:46.693097Z","iopub.status.idle":"2022-09-23T21:32:46.738151Z","shell.execute_reply.started":"2022-09-23T21:32:46.693061Z","shell.execute_reply":"2022-09-23T21:32:46.737326Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Train model\nhistory = model.fit(\n    train_images,\n    validation_data = val_images,\n    batch_size = 32,\n    epochs = 20,\n    callbacks = [\n        tf.keras.callbacks.EarlyStopping(\n            monitor = 'val_loss',\n            patience = 2,\n            restore_best_weights = True\n        )  \n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:32:46.741307Z","iopub.execute_input":"2022-09-23T21:32:46.741611Z","iopub.status.idle":"2022-09-23T21:48:49.237289Z","shell.execute_reply.started":"2022-09-23T21:32:46.741585Z","shell.execute_reply":"2022-09-23T21:48:49.236345Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Epoch 1/20\n1482/1482 [==============================] - 230s 154ms/step - loss: 0.2220 - accuracy: 0.9127 - val_loss: 0.1786 - val_accuracy: 0.9291\nEpoch 2/20\n1482/1482 [==============================] - 106s 71ms/step - loss: 0.1816 - accuracy: 0.9307 - val_loss: 0.1777 - val_accuracy: 0.9284\nEpoch 3/20\n1482/1482 [==============================] - 106s 72ms/step - loss: 0.1681 - accuracy: 0.9358 - val_loss: 0.1731 - val_accuracy: 0.9320\nEpoch 4/20\n1482/1482 [==============================] - 101s 68ms/step - loss: 0.1588 - accuracy: 0.9405 - val_loss: 0.1688 - val_accuracy: 0.9340\nEpoch 5/20\n1482/1482 [==============================] - 106s 71ms/step - loss: 0.1514 - accuracy: 0.9430 - val_loss: 0.1635 - val_accuracy: 0.9386\nEpoch 6/20\n1482/1482 [==============================] - 104s 70ms/step - loss: 0.1444 - accuracy: 0.9460 - val_loss: 0.1629 - val_accuracy: 0.9379\nEpoch 7/20\n1482/1482 [==============================] - 106s 71ms/step - loss: 0.1369 - accuracy: 0.9495 - val_loss: 0.1748 - val_accuracy: 0.9348\nEpoch 8/20\n1482/1482 [==============================] - 102s 69ms/step - loss: 0.1300 - accuracy: 0.9527 - val_loss: 0.1668 - val_accuracy: 0.9368\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create labels dictionary\nlabels = {0: 'female',\n         1: 'male'}","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:48:49.240045Z","iopub.execute_input":"2022-09-23T21:48:49.240850Z","iopub.status.idle":"2022-09-23T21:48:49.245350Z","shell.execute_reply.started":"2022-09-23T21:48:49.240811Z","shell.execute_reply":"2022-09-23T21:48:49.244318Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Create a function for image processing and prediction\ndef output(imagepath):\n    img = image.load_img(imagepath, target_size=(224, 224, 3))\n    img = img_to_array(img)\n    img = img/255\n    img = np.expand_dims(img, [0])\n    \n    answer = model.predict(img)[0]\n    \n    idx = answer.argmax()\n    res = labels[idx]\n    \n    return res","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:48:49.247055Z","iopub.execute_input":"2022-09-23T21:48:49.247399Z","iopub.status.idle":"2022-09-23T21:48:49.257593Z","shell.execute_reply.started":"2022-09-23T21:48:49.247365Z","shell.execute_reply":"2022-09-23T21:48:49.256654Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Predict gender\nimg = output('../input/gender-classification-dataset/Validation/female/112953.jpg.jpg')\nimg","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:48:49.258875Z","iopub.execute_input":"2022-09-23T21:48:49.259407Z","iopub.status.idle":"2022-09-23T21:48:50.122260Z","shell.execute_reply.started":"2022-09-23T21:48:49.259374Z","shell.execute_reply":"2022-09-23T21:48:50.121353Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"'female'"},"metadata":{}}]},{"cell_type":"code","source":"# Save model\nmodel.save('GR.h5')","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:49:28.212714Z","iopub.execute_input":"2022-09-23T21:49:28.213301Z","iopub.status.idle":"2022-09-23T21:49:28.491672Z","shell.execute_reply.started":"2022-09-23T21:49:28.213265Z","shell.execute_reply":"2022-09-23T21:49:28.490721Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"}]}]}